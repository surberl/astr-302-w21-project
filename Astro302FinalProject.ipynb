{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Simple Particle Collider Data Filtration Program </center>\n",
    "#### <center> By Luke Surber, SurberL9@uw.edu </center>\n",
    "### Data from measurements in many experimental contexts is a combination of both the desired signal and background noise (including both systematic and random uncertainty), the signal and noise must be separated in order to correctly study the phenomena without bias. Particle Collider experiments are one such context that interest me, this notebook will serve as a simple filtration program that utilizes widgets to illustrate the process.\n",
    "### Particle colliders have significant implications for the field of HEP, this task of separating noise from signal is absolutely critical to operating a collider (like the LHC for instance) to yield maximum scientific benefit. \n",
    "##### <center> (Last edit: 03/17/2021) </center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420506f93bff4477b3e0b087a4a1425e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=125, description='signal_mean', max=150, min=100), IntSlider(value=60, dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install --upgrade jax jaxlib #Assuming JAX isn't already installed on the local machine being used by the user.\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "key = random.PRNGKey(0)\n",
    "import random as rand\n",
    "import math\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "def toydata(signal_mean,noise_mean,signal_std,noise_std, background_events, cutoff):\n",
    "    size = 100000\n",
    "    mean = jnp.array([signal_mean,noise_mean]).block_until_ready()#block_until_ready helps speed up\n",
    "    cov = jnp.array([[signal_std**2,0],[0,noise_std**2]]).block_until_ready()\n",
    "    x1, x2 = random.multivariate_normal(key, mean, cov, (size,)).T.block_until_ready() \n",
    "    fig, axs = plt.subplots(1,3, figsize=(36,12))\n",
    "    axs[0].set_title(\"Signal and Background Noise\", fontweight=\"bold\", size=20)\n",
    "    axs[0].set_ylabel(\"Events [1/2.5GeV]\", size=20)\n",
    "    axs[0].set_xlabel(\"Energy [GeV]\", size=20)\n",
    "    axs[0].hist(x1, 100, facecolor='darkgreen')\n",
    "    axs[0].hist(x2[:background_events], 100, facecolor='darkblue', alpha=0.5)\n",
    "    axs[0].set_xlim(0,250)\n",
    "    axs[1].set_title(\"Experimentally Measured Data\", fontweight=\"bold\", size=20)\n",
    "    axs[1].set_xlabel(\"Energy [GeV]\", size=20)\n",
    "    axs[1].hist(jnp.concatenate((x1,x2[:background_events])), 100, facecolor='purple')\n",
    "    axs[1].set_xlim(0,250)\n",
    "    axs[2].set_title(\"Filtered Dataset\", fontweight=\"bold\", size=20)\n",
    "    axs[2].set_xlabel(\"Energy [GeV]\", size=20)\n",
    "    axs[2].hist(jnp.concatenate((x1,x2[:background_events]))[jnp.concatenate((x1,x2[:background_events])) > cutoff], 100, facecolor='white')\n",
    "    axs[2].set_xlim(0,250)\n",
    "\n",
    "interact(toydata, background_events=(0,100000,1), signal_mean=(100,150,1), noise_mean=(0,120,1),signal_std=(0.1,50,0.5), noise_std=(0.1,50,0.5), cutoff=(0,250,1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the above plots we see first, two distributions that represent signal (in green) and background noise (in blue), in the second plot we see what instruments see (green+blue), lastly we see the result of our simple filtration method, which is essentially a discrete truncation of the data set; the sliders provide the opportunity to vary this truncation point or \"cutoff\", the other sliders allow for the user to alter the background noise and signal distributions to simulate the possible scenarios that might arise and how it can be filtrated depending on this \"cutoff\" parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRYME: One example of a dataset like this being relevant to HEP would be when the LHC was measuring the mass of the Higgs Boson which is about 125 GeV, try setting signal_mean to 125 GeV and the cutoff to the standard 50GeV, now play around with the other parameters to simulate how simple filtration on a dataset for the Higgs could happen.\n",
    "##### NOTE: the background_events slider indicates the number of events measured that are caused by the background noise, it spans from 0 to one hundred thousand which is the number of signal events (arbitrarily chosen by myself, MUCH higher than what's measured by the LHC). Varying this slider is akin to varying how sensitive the instrumentation is to the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MINOR BUG THAT'S NOT REALLY A BUG: The slider label for background_events isn't displaying the label in it's entirety and this is something I would like to fix, although this is purely aesthetic and doesn't affect the theory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
